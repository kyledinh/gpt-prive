{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyledinh/gpt-prive/blob/main/notebookds/client-to-hf-inference-endpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3BsR0ktOVFo",
        "outputId": "43958e6f-e0ff-46f4-a7e3-0e66b7d4188c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.16.4)\n",
            "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (2023.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (4.6.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.5.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U huggingface_hub python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zDNzF_biO3VF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HF_ACCESS_TOKEN configured\n",
            "HF_ACCESS_URL configured\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# Load .env variables\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "HF_ACCESS_TOKEN = os.getenv(\"HF_ACCESS_TOKEN\", \"add-here-if-not-set-in-env-file\")\n",
        "HF_ENDPOINT_URL = os.getenv(\"HF_ENDPOINT_URL\", \"add-here-if-not-set-in-env-file\")\n",
        " \n",
        "assert os.getenv(\"HF_ACCESS_TOKEN\", \"\").startswith(\"hf_\"), \"This doesn't look like a valid Hugging Face Token\"\n",
        "print(\"HF_ACCESS_TOKEN configured\")\n",
        "assert os.getenv(\"HF_ENDPOINT_URL\", \"\").startswith(\"https\"), \"This doesn't look like a valid Hugging Face Endpoint URL\"\n",
        "print(\"HF_ACCESS_URL configured\")\n",
        "\n",
        "# Streaming Client\n",
        "client = InferenceClient(HF_ENDPOINT_URL, token=HF_ACCESS_TOKEN)\n",
        "\n",
        "# generation parameter\n",
        "gen_kwargs = dict(\n",
        "    max_new_tokens=512,\n",
        "    top_k=30,\n",
        "    top_p=0.9,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.02,\n",
        "    stop_sequences=[\"\\nUser:\", \"<|endoftext|>\", \"</s>\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5_PdgpVQRVf"
      },
      "source": [
        "Non-streaming Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUX3b0IIPW10",
        "outputId": "ed22f511-0108-47db-afa2-250ac9c01bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1. Route 66 - stretching from Chicago to Santa Monica, California, this iconic road offers scenic vistas and diverse landscapes.\n",
            "\n",
            "2. The Blue Ridge Parkway - a 2,000-mile stretch of road that runs through the Appalachian Mountains, providing breathtaking views and winding roads.\n",
            "\n",
            "3. Highway 1 - also known as the Pacific Coast Highway, this coastal road offers stunning vistas of the Pacific Ocean and rugged coastline.\n",
            "\n",
            "4. The Great River Road - a 2,300-mile stretch of road that follows the Mississippi River, providing beautiful landscapes, small towns, and historical sites.\n"
          ]
        }
      ],
      "source": [
        "# prompt\n",
        "prompt = \"What are good motorcycle riding roads in the United States? Give me 4 examples.\"\n",
        "response = client.text_generation(prompt, **gen_kwargs)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73WXwNPCQUNG"
      },
      "source": [
        "Prompt example with Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oJu0gagPFWZ",
        "outputId": "6bb6cc4f-9022-4f28-d8ad-023964ac8beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1. Route 66 (Chicago to Santa Monica, California) 2. The Pacific Coast Highway (San Francisco to Los Angeles) 3. The Blue Ridge Parkway (Virginia to North Carolina) 4. The Great Ocean Road (Victoria, Australia to Adelaide, South Australia)"
          ]
        }
      ],
      "source": [
        "prompt = \"What are good motorcycle riding roads in the United States? Give me 4 examples.\"\n",
        "\n",
        "stream = client.text_generation(prompt, stream=True, details=True, **gen_kwargs)\n",
        "\n",
        "# yield each generated token\n",
        "for r in stream:\n",
        "    # skip special tokens\n",
        "    if r.token.special:\n",
        "        continue\n",
        "    # stop if we encounter a stop sequence\n",
        "    if r.token.text in gen_kwargs[\"stop_sequences\"]:\n",
        "        break\n",
        "    # yield the generated token\n",
        "    print(r.token.text, end = \"\")\n",
        "    # yield r.token.text"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
