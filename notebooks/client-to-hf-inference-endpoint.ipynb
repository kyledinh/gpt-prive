{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyledinh/gpt-prive/blob/main/notebookds/client-to-hf-inference-endpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3BsR0ktOVFo",
        "outputId": "43958e6f-e0ff-46f4-a7e3-0e66b7d4188c"
      },
      "outputs": [],
      "source": [
        "%pip install -U huggingface_hub python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDNzF_biO3VF"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# Load .env variables\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "HF_ACCESS_TOKEN = os.getenv(\"HF_ACCESS_TOKEN\", \"add-here-if-not-set-in-env-file\")\n",
        "HF_ENDPOINT_URL = os.getenv(\"HF_ENDPOINT_URL\", \"add-here-if-not-set-in-env-file\")\n",
        " \n",
        "assert HF_ACCESS_TOKEN.startswith(\"hf_\"), \"This doesn't look like a valid Hugging Face Token\"\n",
        "print(\"HF_ACCESS_TOKEN configured\")\n",
        "assert HF_ENDPOINT_URL.startswith(\"https\"), \"This doesn't look like a valid Hugging Face Endpoint URL\"\n",
        "print(\"HF_ACCESS_URL configured\")\n",
        "\n",
        "# Streaming Client\n",
        "client = InferenceClient(HF_ENDPOINT_URL, token=HF_ACCESS_TOKEN)\n",
        "\n",
        "# generation parameter\n",
        "gen_kwargs = dict(\n",
        "    max_new_tokens=512,\n",
        "    top_k=30,\n",
        "    top_p=0.9,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.02,\n",
        "    stop_sequences=[\"\\nUser:\", \"<|endoftext|>\", \"</s>\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5_PdgpVQRVf"
      },
      "source": [
        "Non-streaming Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUX3b0IIPW10",
        "outputId": "ed22f511-0108-47db-afa2-250ac9c01bfa"
      },
      "outputs": [],
      "source": [
        "# prompt\n",
        "prompt = \"What are good motorcycle riding roads in the United States? Give me 4 examples.\"\n",
        "response = client.text_generation(prompt, **gen_kwargs)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73WXwNPCQUNG"
      },
      "source": [
        "Prompt example with Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oJu0gagPFWZ",
        "outputId": "6bb6cc4f-9022-4f28-d8ad-023964ac8beb"
      },
      "outputs": [],
      "source": [
        "prompt = \"What are good motorcycle riding roads in the United States? Give me 4 examples.\"\n",
        "\n",
        "stream = client.text_generation(prompt, stream=True, details=True, **gen_kwargs)\n",
        "\n",
        "# yield each generated token\n",
        "for r in stream:\n",
        "    # skip special tokens\n",
        "    if r.token.special:\n",
        "        continue\n",
        "    # stop if we encounter a stop sequence\n",
        "    if r.token.text in gen_kwargs[\"stop_sequences\"]:\n",
        "        break\n",
        "    # yield the generated token\n",
        "    print(r.token.text, end = \"\")\n",
        "    # yield r.token.text"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
