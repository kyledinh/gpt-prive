{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Hugging Face TGI to RunPOD\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/kyledinh/gpt-prive/blob/main/codex/deploy-tgi-to-runpod/sample-deploy-tgi-llama2-gptq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "### Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xWBBV67zPCb"
   },
   "outputs": [],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq runpod==0.10.0 --progress-bar off\n",
    "%pip install -qqq text-generation==0.6.0 --progress-bar off\n",
    "%pip install -qqq requests==2.31.0 --progress-bar off\n",
    "\n",
    "import requests\n",
    "import runpod\n",
    "from text_generation import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup .env variables\n",
    "- Create an `.env` with your specific token from your account.\n",
    "- https://www.runpod.io/console/user/settings\n",
    "- https://huggingface.co/settings/tokens\n",
    "\n",
    "```\n",
    "RUNPOD_API_KEY=9M5OM37OK3N5OM37OK3N5OM37OK3NJ875OM37\n",
    "HF_ACCESS_TOKEN=hf_ENv5OM37OK3N5OM37OK3N5OM37OK3N5OM37OK3NT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXshcVfScXr1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "HF_ACCESS_TOKEN = os.getenv(\"HF_ACCESS_TOKEN\", \"hf-some-token\")\n",
    "RUNPOD_API_KEY = os.getenv(\"RUNPOD_API_KEY\", \"add-here-if-not-set-in-env-file\")\n",
    " \n",
    "assert HF_ACCESS_TOKEN.startswith(\"hf_\"), \"This doesn't look like a valid Hugging Face Token\"\n",
    "assert not RUNPOD_API_KEY.startswith(\"add-here\"), \"This doesn't look like a valid Runpod API Key\"\n",
    "\n",
    "runpod.api_key = RUNPOD_API_KEY \n",
    "print(\"HF_ACCESS_TOKEN: \" + HF_ACCESS_TOKEN[0:6])\n",
    "print(\"RUNPOD_API_KEY: \" + runpod.api_key[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy to RunPod\n",
    "- https://www.runpod.io/console/pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rH7Hfx_E3tP",
    "outputId": "56357af8-7460-4364-d0cd-1f40e840e893"
   },
   "outputs": [],
   "source": [
    "podname = \"Sample-deploy-llama2-7B-gptq\"\n",
    "envs = {\"HUGGING_FACE_HUB_TOKEN\":HF_ACCESS_TOKEN, \"QUANTIZE\":\"gptq\"}\n",
    "model = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "gpu_type_id = \"NVIDIA RTX A6000\" # 48GB VRAM $0.79/hr\n",
    "gpu_count = 1\n",
    "# data_center_id=\"EU-RO-1\" | \"EU-CZ-1\" | \"US-KS-1\" | \"US-KS-2\",\n",
    "\n",
    "pod = runpod.create_pod(\n",
    "    name=podname,\n",
    "    image_name=\"ghcr.io/huggingface/text-generation-inference:1.0.3\",\n",
    "    gpu_type_id=gpu_type_id,\n",
    "    cloud_type=\"SECURE\",\n",
    "    data_center_id=\"US-KS-1\",\n",
    "    docker_args=\"--model-id \" + model,\n",
    "    gpu_count=gpu_count,\n",
    "    volume_in_gb=50,\n",
    "    container_disk_in_gb=10,\n",
    "    ports=\"80/http,29500/http\",\n",
    "    volume_mount_path=\"/data\",\n",
    "    env=envs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCHpvkP7xK-8",
    "outputId": "10010d02-7737-4e60-b51a-a3cc03e17225"
   },
   "outputs": [],
   "source": [
    "SERVER_URL = f'https://{pod[\"id\"]}-80.proxy.runpod.net'\n",
    "print(SERVER_URL)\n",
    "print(f\"Docs (Swagger UI) URL: {SERVER_URL}/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noBOoZWnQLpt"
   },
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
    "    return f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{prompt} [/INST]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQy8bxQveGK9"
   },
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGFB1tzbwnpl"
   },
   "outputs": [],
   "source": [
    "def make_request(prompt: str):\n",
    "    data = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\"best_of\": 1, \"temperature\": 0.01, \"max_new_tokens\": 512},\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    return requests.post(f\"{SERVER_URL}/generate\", json=data, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tY0w6HQc33JW",
    "outputId": "6cc0935a-7482-4ee8-d9eb-5f986e85380d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = generate_prompt(\n",
    "    \"Write an email to a new client to offer a subscription for a paper supply for 1 year.\"\n",
    ")\n",
    "response = make_request(prompt)\n",
    "response.status_code\n",
    "print(response.json()[\"generated_text\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlS6f0C706PF"
   },
   "outputs": [],
   "source": [
    "DWIGHT_SYSTEM_PROMPT = \"\"\"\n",
    "You're a salesman and beet farmer know as Dwight K Schrute from the TV show The Office. Dwgight replies just as he would in the show.\n",
    "You always reply as Dwight would reply. If you don't know the answer to a question, please don't share false information. Always format your responses using markdown.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKOxCja24GxF",
    "outputId": "06cce64d-0e99-46fb-d60f-4c8236f61bdd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = generate_prompt(\n",
    "    \"Write an email to a new client to offer a subscription for a paper supply for 1 year.\",\n",
    "    system_prompt=DWIGHT_SYSTEM_PROMPT,\n",
    ")\n",
    "response = make_request(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5KYz08e8XIc",
    "outputId": "f3fca4a1-2ce2-4a73-b6d1-f8b311862174"
   },
   "outputs": [],
   "source": [
    "print(response.json()[\"generated_text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rP6xNXoqeFDS"
   },
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1TEA2LveITs"
   },
   "outputs": [],
   "source": [
    "client = Client(SERVER_URL, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M13GjP-i4jgs",
    "outputId": "7392193a-6ac5-4efd-d6d0-177c9403151e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = client.generate(prompt, max_new_tokens=512).generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dao9ZaNy4zBX",
    "outputId": "79c9a8f2-d612-44b0-9f22-6af1ab87938b"
   },
   "outputs": [],
   "source": [
    "print(response.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwzBhtHIyDzs",
    "outputId": "35fbf997-4437-4f13-962c-a80320b2907c"
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for response in client.generate_stream(prompt, max_new_tokens=512):\n",
    "    if not response.token.special:\n",
    "        new_text = response.token.text\n",
    "        print(new_text, end=\"\")\n",
    "        text += new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owo7RuELe3aP"
   },
   "outputs": [],
   "source": [
    "runpod.terminate_pod(pod[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h1REGtGMc28"
   },
   "source": [
    "## References\n",
    "\n",
    "- https://www.runpod.io/console/gpu-secure-cloud\n",
    "- https://docs.runpod.io/docs/get-gpu-types\n",
    "- https://github.com/facebookresearch/llama\n",
    "- https://github.com/huggingface/text-generation-inference\n",
    "- https://github.com/runpod/runpod-python\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
