{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1xWBBV67zPCb"
   },
   "outputs": [],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq runpod==0.10.0 --progress-bar off\n",
    "%pip install -qqq text-generation==0.6.0 --progress-bar off\n",
    "%pip install -qqq requests==2.31.0 --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IxyMPJBGzhLF"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import runpod\n",
    "from text_generation import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "BXshcVfScXr1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HUB_TOKEN: hf_ENv\n",
      "RUNPOD_API_KEY: 9MJ87C\n"
     ]
    }
   ],
   "source": [
    "import runpod\n",
    "# Load .env variables\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "HF_HUB_TOKEN = os.getenv(\"HF_HUB_TOKEN\", \"hf-some-token\")\n",
    "RUNPOD_API_KEY = os.getenv(\"RUNPOD_API_KEY\", \"add-here-if-not-set-in-env-file\")\n",
    " \n",
    "assert HF_HUB_TOKEN.startswith(\"hf_\"), \"This doesn't look like a valid Hugging Face Token\"\n",
    "print(\"HF_HUB_TOKEN: \" + HF_HUB_TOKEN[0:6])\n",
    "assert not RUNPOD_API_KEY.startswith(\"add-here\"), \"This doesn't look like a valid Runpod API Key\"\n",
    "runpod.api_key = RUNPOD_API_KEY \n",
    "print(\"RUNPOD_API_KEY: \" + runpod.api_key[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rH7Hfx_E3tP",
    "outputId": "56357af8-7460-4364-d0cd-1f40e840e893"
   },
   "outputs": [],
   "source": [
    "gpu_count = 1\n",
    "\n",
    "envs = {\"HUGGING_FACE_HUB_TOKEN\":HF_HUB_TOKEN}\n",
    "\n",
    "    # data_center_id=\"EU-RO-1\",\n",
    "    # data_center_id=\"US-KS-1\",\n",
    "    # docker_args=\"--model-id TheBloke/Llama-2-7b-chat-fp16 --env HUGGING_FACE_HUB_TOKEN=hf_foo\",\n",
    "pod = runpod.create_pod(\n",
    "    name=\"Llama-7b-sample\",\n",
    "    image_name=\"ghcr.io/huggingface/text-generation-inference:0.9.4\",\n",
    "    gpu_type_id=\"NVIDIA RTX A4500\",\n",
    "    cloud_type=\"SECURE\",\n",
    "    data_center_id=\"EU-RO-1\",\n",
    "    docker_args=\"--model-id TheBloke/Llama-2-7b-chat-fp16\",\n",
    "    gpu_count=gpu_count,\n",
    "    volume_in_gb=50,\n",
    "    container_disk_in_gb=5,\n",
    "    ports=\"80/http,29500/http\",\n",
    "    volume_mount_path=\"/data\",\n",
    "    env=envs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCHpvkP7xK-8",
    "outputId": "10010d02-7737-4e60-b51a-a3cc03e17225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i4fu3rms6p2hoa-80.proxy.runpod.net\n"
     ]
    }
   ],
   "source": [
    "SERVER_URL = f'https://{pod[\"id\"]}-80.proxy.runpod.net'\n",
    "print(SERVER_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kSXFcZMtlxT",
    "outputId": "21e17fa0-ce2d-4107-f0a3-abe116b25947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs (Swagger UI) URL: https://i4fu3rms6p2hoa-80.proxy.runpod.net/docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Docs (Swagger UI) URL: {SERVER_URL}/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "noBOoZWnQLpt"
   },
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
    "    return f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{prompt} [/INST]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQy8bxQveGK9"
   },
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "VGFB1tzbwnpl"
   },
   "outputs": [],
   "source": [
    "def make_request(prompt: str):\n",
    "    data = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\"best_of\": 1, \"temperature\": 0.01, \"max_new_tokens\": 512},\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    return requests.post(f\"{SERVER_URL}/generate\", json=data, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tY0w6HQc33JW",
    "outputId": "6cc0935a-7482-4ee8-d9eb-5f986e85380d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 ms, sys: 3.45 ms, total: 22.6 ms\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = generate_prompt(\n",
    "    \"Write an email to a new client to offer a subscription for a paper supply for 1 year.\"\n",
    ")\n",
    "response = make_request(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkgRbVaIyvZx",
    "outputId": "b8f84929-8bc0-4dcc-a46e-54bad4228674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c_u8wGe4AO5",
    "outputId": "2eaf0421-0a69-410f-cec3-f7d7cbcaecc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Welcome to [Company Name] - Paper Supply Subscription Offer\n",
      "Dear [Client Name],\n",
      "We are thrilled to welcome you to [Company Name], and we hope you're doing well! As a valued client, we're excited to offer you a special subscription deal for a year's supply of high-quality paper products.\n",
      "Our paper supply subscription service is designed to provide you with a convenient and cost-effective way to stock up on the paper products you need, without any hassle or waste. With our subscription, you'll receive a regular shipment of paper products, tailored to your specific needs and preferences.\n",
      "Here's what you can expect with our subscription service:\n",
      "* A wide range of paper products, including A4, A3, A2, A1, and custom sizes\n",
      "* High-quality, durable paper that's perfect for printing, writing, and crafting\n",
      "* Regular shipments every [insert time frame, e.g., monthly, quarterly, etc.]\n",
      "* Flexible subscription plans to suit your needs and budget\n",
      "* Easy online management and tracking of your subscription\n",
      "* Excellent customer support and prompt delivery\n",
      "We're confident that our subscription service will help you save time and money, while ensuring you always have a steady supply of high-quality paper products on hand. Plus, with our flexible subscription plans, you can easily adjust your order as your needs change.\n",
      "To take advantage of this offer, simply reply to this email with your preferred subscription plan and shipping details. Our team will take care of the rest, and your first shipment will be on its way shortly.\n",
      "Thank you for choosing [Company Name]. We look forward to serving you!\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Company Name]\n",
      "[Contact Information]\n"
     ]
    }
   ],
   "source": [
    "print(response.json()[\"generated_text\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlS6f0C706PF"
   },
   "outputs": [],
   "source": [
    "DWIGHT_SYSTEM_PROMPT = \"\"\"\n",
    "You're a salesman and beet farmer know as Dwight K Schrute from the TV show The Office. Dwgight replies just as he would in the show.\n",
    "You always reply as Dwight would reply. If you don't know the answer to a question, please don't share false information. Always format your responses using markdown.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKOxCja24GxF",
    "outputId": "06cce64d-0e99-46fb-d60f-4c8236f61bdd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = generate_prompt(\n",
    "    \"Write an email to a new client to offer a subscription for a paper supply for 1 year.\",\n",
    "    system_prompt=DWIGHT_SYSTEM_PROMPT,\n",
    ")\n",
    "response = make_request(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5KYz08e8XIc",
    "outputId": "f3fca4a1-2ce2-4a73-b6d1-f8b311862174"
   },
   "outputs": [],
   "source": [
    "print(response.json()[\"generated_text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rP6xNXoqeFDS"
   },
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1TEA2LveITs"
   },
   "outputs": [],
   "source": [
    "client = Client(SERVER_URL, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M13GjP-i4jgs",
    "outputId": "7392193a-6ac5-4efd-d6d0-177c9403151e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = client.generate(prompt, max_new_tokens=512).generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dao9ZaNy4zBX",
    "outputId": "79c9a8f2-d612-44b0-9f22-6af1ab87938b"
   },
   "outputs": [],
   "source": [
    "print(response.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwzBhtHIyDzs",
    "outputId": "35fbf997-4437-4f13-962c-a80320b2907c"
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for response in client.generate_stream(prompt, max_new_tokens=512):\n",
    "    if not response.token.special:\n",
    "        new_text = response.token.text\n",
    "        print(new_text, end=\"\")\n",
    "        text += new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owo7RuELe3aP"
   },
   "outputs": [],
   "source": [
    "runpod.terminate_pod(pod[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h1REGtGMc28"
   },
   "source": [
    "## References\n",
    "\n",
    "- https://www.runpod.io/console/gpu-secure-cloud\n",
    "- https://docs.runpod.io/docs/get-gpu-types\n",
    "- https://github.com/facebookresearch/llama"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
